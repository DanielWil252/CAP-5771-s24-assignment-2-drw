import numpy as np
from sklearn import cluster
from sklearn.preprocessing import StandardScaler


#euclidian distance function.
def euclidean_distance(x,y):
    return np.sqrt(np.sum((x - y) ** 2))


#modified fit_kmeans for question 2d that returns inertia.
def fit_kmeans_inertia(dataset, n_clusters):
    #Filter data 
    data, _, _ = dataset
    
    #Standardize scale with StandardScaler()
    scaler = StandardScaler()
    data_std = scaler.fit_transform(data)

    #Initialize kmeans
    kmeans = cluster.KMeans(n_clusters=n_clusters, init='random', random_state=42)

    #Fit data.
    kmeans.fit(data_std)
    #Return inertia.

    return kmeans.inertia_


#GENERATED BY CHATGPT -- confirming intial guess of 4 for question 3c.
def find_merge_iteration(Z, cluster_I, cluster_J):

    n = Z.shape[0] + 1  # Number of initial clusters

    cluster_dict = {i: [i] for i in range(n)}  # Initialize clusters with single elements

    

    # Iterate over the linkage matrix

    for i, merge_info in enumerate(Z):

        # The indices in the linkage matrix are n-1, so we add n to the row index

        new_cluster_idx = i + n

        # The clusters being merged in the current iteration

        cluster1_idx, cluster2_idx = int(merge_info[0]), int(merge_info[1])

        

        # Check if the indices being merged match the input clusters or their elements

        if (set(cluster_dict[cluster1_idx]) == set(cluster_I) and set(cluster_dict[cluster2_idx]) == set(cluster_J)) or (set(cluster_dict[cluster1_idx]) == set(cluster_J) and set(cluster_dict[cluster2_idx]) == set(cluster_I)):

            return i  # Return the current iteration if a match is found

        

        # Update the cluster dictionary with the new merge

        cluster_dict[new_cluster_idx] = cluster_dict[cluster1_idx] + cluster_dict[cluster2_idx]

        # Delete the old clusters as they are now merged

        del cluster_dict[cluster1_idx], cluster_dict[cluster2_idx]

    return None
